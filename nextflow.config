/*
 * -------------------------------------------------
 *  nf-core/catastroflow Nextflow config file
 * -------------------------------------------------
 * Default config options for all environments.
 */

manifest {
  name = 'catastrophy-pipeline'
  author = 'Darcy Jones'
  homePage = 'https://github.com/ccdmb/catastrophy-pipeline'
  description = 'Run the catastrophy classifier for many genomes.'
  mainScript = 'main.nf'
  nextflowVersion = '>=0.32.0'
  version = 'v0.0.1'
}


// Global default params, used in configs
params {

  // Workflow flags
  // TODO nf-core: Specify your pipeline's command line flags
  proteomes = false
  dbcan = false
  dbcan_version = false
  dbcan_url = false

  outdir = './results'

  // Boilerplate options
  name = false
  help = false
  tracedir = "${params.outdir}/pipeline_info"
}

// Container slug. Stable releases should specify release tag!
// Developmental code should specify :dev
process.container = "darcyabjones/${manifest.name}:${manifest.version}"

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'


profiles {
  conda { process.conda = "$baseDir/environment.yml" }
  debug { process.beforeScript = 'echo $HOSTNAME' }
  docker { docker.enabled = true }
  docker_sudo {
    docker.enabled = true
    docker.sudo = true
  }
  singularity { singularity.enabled = true }
  test { includeConfig 'conf/test.config' }
}

// Avoid this error:
// WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.
// Testing this in nf-core after discussion here https://github.com/nf-core/tools/pull/351, once this is established and works well, nextflow might implement this behavior as new default.
//docker.runOptions = '-u \$(id -u):\$(id -g)'


// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

timeline {
  enabled = true
  file = "${params.tracedir}/execution_timeline.html"
}
report {
  enabled = true
  file = "${params.tracedir}/execution_report.html"
}
trace {
  enabled = true
  file = "${params.tracedir}/execution_trace.txt"
}
dag {
  enabled = true
  file = "${params.tracedir}/pipeline_dag.svg"
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if (type == 'memory') {
    try {
      if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'time') {
    try {
      if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'cpus') {
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}
